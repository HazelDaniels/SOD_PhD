# Reading in the data

```{r}
library(vcfR)
library(tidyverse)
vcf <- read.vcfR("C:\\Users\\hazel\\Google Drive\\_Ph.D. Forestry\\Research\\2018.06_SpatialAnalysis\\Data\\Illumina datafiles\\ramorum.vcf.gz")
raw.vcf <- nrow(vcf)
```


# Calculating the number of polymorphic sites and removing all non-biallelic sites
```{r}
vcf <- vcf[is.polymorphic(vcf, na.omit = T)]
poly.vcf <- nrow(vcf)
vcf <- vcf[is.biallelic(vcf)]
biallelic.vcf <- nrow(vcf)
```

246, 241 (down from 277,225) Polymorphic sites
238, 188 (down from 271,578) Biallelic sites

# Filtering by DP:

```{R}
dp.vc <- extract.gt(vcf, element = "DP", as.numeric = T)
gt.vc <- extract.gt(vcf, element = "GT", as.numeric = T)
## dp.vc backup
dp.vc.bk <- dp.vc
gt.vc.bk <- gt.vc
```

## Filtering by DP (DP (10x < x > 95%))

```{r}
## Creating quantiles based in the lower 5% and the higher 95%
sums <- apply(dp.vc.bk, 2, function (x) quantile(x, probs=c(0.05, 0.50, 0.95), na.rm = T))
## Here is where we add the min depth (10x)
sums[1,][sums[1,] < 10] <- 10
dp.all.2 <- sweep(dp.vc.bk, MARGIN=2, FUN="-", sums[1,])
dp.vc[dp.all.2 <= 0] <- NA
dp.all.2 <- sweep(dp.vc.bk, MARGIN=2, FUN="-", sums[3,])
dp.vc[dp.all.2 > 0] <- NA
# Changing GT
vcf@gt[,-1][is.na(dp.vc)] <- NA
```

# Filtering by maximum MQ (MQ == 50)

```{r}
mq <- extract.info(vcf, element = "MQ", as.numeric = T)
## Creating mask
mask.mq <- rep(T, nrow(vcf))
## Filtering in the mast
mask.mq[mq < 50] <- F
```

Regions removed by MQ: `r  biallelic.vcf - sum(mask.mq)`

# Filtering on MAF (minor allele freq)

```{r}
maf.tresh <- 2/(ncol(vcf@gt[,-1]))
cat("MAF threshold:", maf.tresh, "\n")
## Creating mask
library(stringr)
mask.maf <- rep(T, nrow(vcf))
## Extracting GT info and calculating MAF
class(gt.vc) <- 'numeric'
mask.maf <- apply(gt.vc, 1, function (x) min(table(x)))/ncol(vcf@gt) >= maf.tresh
```

Regions removed by MAF: `r biallelic.vcf - sum(mask.maf)`

# Filtering by missing data:

```{r}
mask.miss <- rep(T, nrow(vcf))
gt.vc <- extract.gt(vcf, element = "GT", as.numeric = T)
mask.miss <- apply(gt.vc, 1, function (x) sum(is.na(x))/ncol(gt.vc)) <= 0.00
```

Regions removed by MAF: `r biallelic.vcf - sum(mask.miss)`

## Missing DP per sample (Missing more than 20% data)

Why 20% data? Because is the maximum percentage of missing data to filter in order to keep most data.

```{r}
h <- apply(dp.vc, 2, function (x) is.na(x) %>% sum/nrow(dp.vc)) %>% hist()
h$density = h$counts/sum(h$counts)*100
plot(h,freq=FALSE)
```

```{r}
missing.samples <- colnames(dp.vc)[apply(dp.vc, 2, function (x) is.na(x) %>% sum/nrow(dp.vc)) > 0.2]
vcf@gt <- vcf@gt[,!colnames(vcf@gt) %in% missing.samples]
mask.miss <- rep(T, nrow(vcf))
gt.vc <- extract.gt(vcf, element = "GT", as.numeric = T)
mask.miss <- apply(gt.vc, 1, function (x) sum(is.na(x))/ncol(gt.vc)) <= 0.00
```

# Processing masks

```{r}
mask.vcf <- cbind(mask.mq, mask.maf, mask.miss)
filtered.vcf <- vcf[apply(mask.vcf, 1, sum) == 3,]
filtered.vcf
write.vcf(filtered.vcf, file = "Final.vcf.gz", mask = F)
```

Did the new filtering by DP work?
```{r}
# DP from the new filtered data:
dp.filtered <- extract.gt(filtered.vcf, element = "DP", as.numeric = T)
apply(dp.filtered, 1, min) %>% hist(xlab="Minimum DP", main="Histogram of minimum DP per variant site", border="grey70", col="grey90", breaks=10,  xlim=c(10,20))
library(reshape2)
dpf <- melt(dp.filtered, varnames=c('Index', 'Sample'), value.name = 'Depth', na.rm=TRUE)
p <- ggplot(dpf, aes(x=Sample, y=Depth)) + geom_violin(fill="#C0C0C0", adjust=1.0,
                                                         scale = "count", trim=TRUE)
p <- p + theme_bw()
p <- p + theme(axis.title.x = element_blank(), 
               axis.text.x = element_text(angle = 60, hjust = 1, size=12))
p <- p + scale_y_continuous(trans=scales::log2_trans(), 
                              breaks=c(1, 10, 100, 800),
                              minor_breaks=c(1:10, 2:10*10, 2:8*100))
p <- p + theme(axis.title.y = element_text(size=12))
p <- p + theme( panel.grid.major.y=element_line(color = "#A9A9A9", size=0.6) )
p <- p + theme( panel.grid.minor.y=element_line(color = "#C0C0C0", size=0.2) )
p <- p + stat_summary(fun.y=median, geom="point", shape=23, size=2)
p
```
